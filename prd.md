PRD: Saw This Before: Automated Issue Triage & Prioritization (for Cursor agents)

1) Overview

Build a GitHub-integrated app that reads new/updated issues and (a) detects duplicates, (b) auto-labels, (c) assigns/ routes to the right owner/team, and (d) outputs a priority score with rationale. Operates in ‚Äúsuggest‚Äù mode first (human in the loop), then ‚Äúauto-apply‚Äù above confidence thresholds.

2) Goals / Non-Goals

Goals
	‚Ä¢	Cut human triage time per issue by ‚â•60%.
	‚Ä¢	Merge/close obvious duplicates automatically (‚â•80% precision in suggest mode).
	‚Ä¢	Produce consistent labels/assignees within 30s of issue creation/edit.
	‚Ä¢	Provide transparent rationale and links to similar issues.

Non-Goals (v1)
	‚Ä¢	Full bug reproduction.
	‚Ä¢	Cross-tracker support beyond GitHub (Jira, Linear) ‚Äî optional later.
	‚Ä¢	Vulnerability scanning or CI test triage (out of scope v1).

3) Primary Users & Flows
	‚Ä¢	Maintainers/Triage team: review suggestions, approve/override.
	‚Ä¢	Engineers: receive routed issues, see summary + similar tickets.
	‚Ä¢	PMs: review weekly triage analytics.

High-level flow
	1.	GitHub webhook ‚Üí ingest event.
	2.	Normalize text (title/body/top comments).
	3.	Vector search for near-dupes ‚Üí candidate set.
	4.	LLM classifies labels, priority, component; dedup check; owner routing.
	5.	Post single triage comment + apply changes if above thresholds.
	6.	Persist decisions & metrics.

4) Success Metrics (v1)
	‚Ä¢	Mean time from issue open ‚Üí first triage: <30s.
	‚Ä¢	Maintainer acceptance rate of suggestions: ‚â•75%.
	‚Ä¢	Duplicate detection F1 (on holdout data): ‚â•0.8.
	‚Ä¢	Label accuracy (top-k=3): ‚â•0.85.
	‚Ä¢	SLA: 99.9% uptime for webhook receiver.

‚∏ª

5) System Architecture (Base Infra & Tech Stack)

Runtime
	‚Ä¢	Backend: TypeScript / Node.js (NestJS)
	‚Ä¢	Workers/Orchestration: Temporal.io (preferred) or BullMQ
	‚Ä¢	Admin/UI (optional v1.5): Next.js + Tailwind
	‚Ä¢	DB: Postgres (pgvector) for embeddings + metadata
	‚Ä¢	Search (optional): OpenSearch if we need hybrid lexical/vector
	‚Ä¢	Cache/Queue: Redis
	‚Ä¢	Object store: S3/GCS for embeddings snapshots (optional)
	‚Ä¢	Containers: Docker; deploy to AWS/GCP/Fly.io
	‚Ä¢	Secrets: AWS Secrets Manager / GCP Secret Manager
	‚Ä¢	Observability: OpenTelemetry ‚Üí Grafana/Cloud Monitoring; structured logs

LLM/Embedding
	‚Ä¢	Embeddings: OpenAI text-embedding-3-large or similar; pluggable.
	‚Ä¢	LLM: Provider-agnostic; start with Claude or GPT-4.1.
	‚Ä¢	Guardrails: JSON schemas; retry/pattern checks.

Security
	‚Ä¢	GitHub App with least-privilege permissions.
	‚Ä¢	Token rotation; per-installation tokens; encryption at rest (KMS).
	‚Ä¢	Full audit log of auto-actions + human overrides.

‚∏ª

6) Required Integrations & APIs

GitHub App (preferred over OAuth)
	‚Ä¢	Webhooks: issues, issue_comment, label, project_v2_item, repository
	‚Ä¢	REST v3 (minimum):
	‚Ä¢	Issues: GET/POST /repos/{owner}/{repo}/issues
	‚Ä¢	Labels: GET/POST /repos/{owner}/{repo}/labels, POST /issues/{number}/labels
	‚Ä¢	Comments: POST /issues/{number}/comments
	‚Ä¢	Assignees: POST /issues/{number}/assignees
	‚Ä¢	Search: GET /search/issues (candidate retrieval)
	‚Ä¢	Projects v2 fields (if used)
	‚Ä¢	GraphQL v4 (batch/complex queries):
	‚Ä¢	Fetch issue nodes (title, body, reactions, labels, timelineItems)
	‚Ä¢	CODEOWNERS-like ownership via teams/paths (if exposed; else local mapping)
	‚Ä¢	Rate limits: handle secondary rate limit; exponential backoff; queue.

(Optional later) Slack
	‚Ä¢	Slash command /triage to preview/apply suggestions.
	‚Ä¢	Events API for notifications.

Internal API (our service)
	‚Ä¢	POST /ingest/github (webhook receiver)
	‚Ä¢	GET /issues/{id}/triage (current suggestion)
	‚Ä¢	POST /issues/{id}/apply (force apply)
	‚Ä¢	GET /analytics/weekly

‚∏ª

7) Data Model (core tables)
	‚Ä¢	repo_installation(id, owner, repo, installation_id, settings_json)
	‚Ä¢	issue(id, repo_id, number, title, body, state, author, created_at, updated_at)
	‚Ä¢	issue_embedding(issue_id, vector, model, ts) (pgvector)
	‚Ä¢	triage_suggestion(id, issue_id, labels[], assignees[], priority_score, duplicate_of?, confidence_json, rationale, created_at)
	‚Ä¢	decision_log(id, issue_id, action, actor, payload_json, created_at)
	‚Ä¢	similar_link(issue_id, similar_issue_id, score)
	‚Ä¢	routing_map(component, team_slug, codeowners_paths[])
	‚Ä¢	metrics_daily(date, repo_id, suggestions, accepted, auto_applied, dupes_closed)

‚∏ª

8) Triage Pipeline (LLM + retrieval)

P0 Signals
	‚Ä¢	Title, body, first N comments, stack trace snippets, version tags, release notes references, reactions, linked PRs, mention density, past reporter history.

Stages
	1.	Ingest & Normalize
	‚Ä¢	Strip boilerplate, code fences retained, extract version/OS.
	2.	Candidate Retrieval (ANN)
	‚Ä¢	Embed (title + body), k-NN via pgvector.
	‚Ä¢	Hybrid boost if same label/version keywords present.
	3.	Near-Dupe Check (LLM gate)
	‚Ä¢	Prompt compares current issue vs top-k candidates ‚Üí returns duplicate_of (issue id) + confidence.
	4.	Auto-Label (multi-label)
	‚Ä¢	Classifier head (few-shot LLM) + rules from historical labels.
	‚Ä¢	Confidence per label; only apply > threshold; else propose.
	5.	Routing/Assignment
	‚Ä¢	Map component ‚Üí team (from CODEOWNERS or custom map).
	‚Ä¢	If ambiguous, propose 2 teams with rationale.
	6.	Priority Scoring (deterministic + LLM weighting)
	‚Ä¢	P = w1*Impact + w2*BlastRadius + w3*UserPain + w4*Freshness + w5*ReproEvidence + w6*ReporterTrust
	‚Ä¢	Impact: mentions of crash/data loss, # of watchers/reactions, occurrence keywords.
	‚Ä¢	BlastRadius: core packages/components.
	‚Ä¢	UserPain: ‚Äúblocking‚Äù, ‚Äúcannot start‚Äù, ‚Äúproduction‚Äù.
	‚Ä¢	Freshness: new release tag referenced.
	‚Ä¢	ReproEvidence: steps, logs, env.
	‚Ä¢	ReporterTrust: reporter‚Äôs historical accepted issues ratio.
	‚Ä¢	LLM provides weights; final score clamped 0‚Äì100; rationale string.
	7.	Action Layer
	‚Ä¢	Post single triage comment (summary, labels, assignees, priority, dupes).
	‚Ä¢	Apply labels/assignee automatically if confidence ‚â• œÑ.
	‚Ä¢	If duplicate with high confidence, comment and (optionally) close as dupe linking canonical.

Comment template (single post)

üß≠ Triage suggestions (v1)
‚Ä¢ Labels: [bug, ui] (conf 0.86)
‚Ä¢ Assignee/Team: @org/ui-team (conf 0.78)
‚Ä¢ Priority: 82/100 ‚Äî likely crash on startup in v1.8.2
‚Ä¢ Possible duplicate(s): #1234 (0.92), #1199 (0.81)
Why: crash keywords + stack trace match; same version tag; reporter history high quality.
Actions: ‚úÖ Apply all | üéØ Apply labels | üë• Assign | üîó Mark duplicate


‚∏ª

9) Cursor Agents Plan (multi-agent prompts)

Agents
	‚Ä¢	Ingest Agent: cleanse/structure incoming payloads; extract metadata.
	‚Ä¢	Retriever Agent: vector search + lexical; returns top-k with reason.
	‚Ä¢	Dedup Agent: pairwise LLM comparison; outputs canonical match + confidence.
	‚Ä¢	Classifier Agent: propose labels/components; JSON output with confidences.
	‚Ä¢	Router Agent: map to owner/team; cite CODEOWNERS/routing_map evidence.
	‚Ä¢	Prioritizer Agent: compute priority score; return score + rationale.
	‚Ä¢	Supervisor/Orchestrator: merges outputs; enforces thresholds; formats GitHub comment; decides apply vs suggest.

Shared system prompt (all agents)
	‚Ä¢	Always return valid JSON conforming to provided schema.
	‚Ä¢	Provide short rationale (‚â§50 words).
	‚Ä¢	Never invent issue numbers; only from candidate set.

JSON contracts (abbrev)

// Dedup Agent
{ "duplicate_of": 1234, "confidence": 0.92, "alternates": [1199] , "rationale": "..." }

// Classifier Agent
{ "labels": [{"name":"bug","conf":0.91},{"name":"ui","conf":0.78}], "components":[{"name":"renderer","conf":0.74}], "rationale":"..." }

// Router Agent
{ "assignees": ["org/ui-team"], "conf": 0.8, "evidence": ["CODEOWNERS:path/ui/*"], "rationale": "..." }

// Prioritizer
{ "priority": 82, "factors": {"impact":0.9,"blast_radius":0.7,"user_pain":0.8,"freshness":0.6,"repro":0.7,"trust":0.8}, "rationale":"..." }


‚∏ª

10) Phased Delivery & Prioritized Backlog

Phase 0 ‚Äî Spike (Week 1‚Äì2)
	‚Ä¢	GitHub App scaffold + webhook receiver.
	‚Ä¢	Postgres + pgvector; embedding job.
	‚Ä¢	Minimal ANN retrieval; log-only suggestions.
	‚Ä¢	Success: pipeline runs end-to-end in staging.

Phase 1 ‚Äî MLP (Minimum Lovable Product) (Week 3‚Äì6)
	‚Ä¢	P1: Triage comment with labels/assignee/priority + similar issues.
	‚Ä¢	P1: Confidence thresholds + ‚Äúsuggest vs auto-apply‚Äù switch per repo.
	‚Ä¢	P1: Admin toggles (per-label thresholds); audit log.
	‚Ä¢	P2: Simple duplicate ‚Äúclose as dupe‚Äù (manual confirm button).
	‚Ä¢	P2: Weekly analytics email.
	‚Ä¢	P3: Slack preview command.

Phase 2 ‚Äî Quality & Scale (Week 7‚Äì10)
	‚Ä¢	P1: Dupe auto-close above high confidence; link canonical.
	‚Ä¢	P1: Routing map import from CODEOWNERS; team mapping UI.
	‚Ä¢	P1: A/B evaluation harness; offline labeled set; dashboard.
	‚Ä¢	P2: Project v2 field updates (priority/status).
	‚Ä¢	P2: Rate-limit batching via GraphQL.
	‚Ä¢	P3: Multi-repo, org-wide settings.

Phase 3 ‚Äî Enterprise (Week 11‚Äì14)
	‚Ä¢	P1: SSO, audit exports, PII policy, data retention.
	‚Ä¢	P1: Fine-tuned label classifier per repo (optional adapter).
	‚Ä¢	P2: Human-in-the-loop UI (approve/override queue).
	‚Ä¢	P2: SLA alerts if triage queue backs up.
	‚Ä¢	P3: Slack/Teams rich actions.

Backlog (impact/effort)

Item	Impact	Effort
Triage comment w/ labels+assignee+priority	High	Low
Near-dupe detection (retrieval + LLM)	High	Med
Auto-apply w/ thresholds	High	Low
Auto-close duplicates	High	Med
Routing from CODEOWNERS	Med	Low
Analytics & eval harness	Med	Med
Slack preview/apply	Med	Med


‚∏ª

11) Config & Policies
	‚Ä¢	Per-repo settings: thresholds, auto-apply toggles, labels excluded from auto.
	‚Ä¢	Privacy: minimize data retention; redact emails/tokens; configurable retention window (e.g., 90 days).
	‚Ä¢	Compliance: SOC2-friendly logging and access controls.

‚∏ª

12) Error Handling & Edge Cases
	‚Ä¢	Huge issues (>100k chars): summarize chunked, skip attachments.
	‚Ä¢	Non-English issues: auto-detect language, translate for embedding, preserve original.
	‚Ä¢	Rate limits: queue + backoff; partial updates; idempotent operations.
	‚Ä¢	Private repos: respect scopes; never leak references across repos.
	‚Ä¢	Flapping edits: debounce (e.g., 10s window) before triage run.

‚∏ª

13) Testing & Evaluation
	‚Ä¢	Golden set: sample 500 historical issues hand-labeled (dupe/not, labels, owner).
	‚Ä¢	Offline metrics: precision/recall for dupes; label accuracy; routing accuracy; calibration curves for confidence.
	‚Ä¢	Canary: suggest-only in 1‚Äì2 repos, track acceptance.
	‚Ä¢	Load: 100 RPS webhook burst; ensure <30s median triage.

‚∏ª

14) DevOps
	‚Ä¢	CI: lint, typecheck, unit tests, contract tests for JSON schemas.
	‚Ä¢	CD: blue/green deploy; DB migrations w/ Prisma or TypeORM.
	‚Ä¢	Feature flags via LaunchDarkly/OpenFF.

‚∏ª

15) Prompts (seed examples)

Dedup Agent (pairwise)

System: You compare a new issue to a candidate issue. If they describe the same underlying problem, return duplicate_of=true with short reason. Consider version, stack trace, steps.

User:
NEW:
Title: "Crash on startup v1.8.2 on macOS 14.5"
Body: "After updating to v1.8.2, app crashes at launch. Stack trace: ..."

CANDIDATE #1234:
Title: "App crashes on macOS Sonoma after 1.8.2"
Body: "Immediate crash with signal 11, trace ..."

Return JSON: {"duplicate": true, "confidence": 0.92, "rationale": "..."}

Classifier Agent

System: Propose labels (multi-label) and component. Use only existing labels list. Return confidences 0-1.

User:
Repo labels: ["bug","feature","docs","ui","cli","build"]
Issue text: "Clicking the avatar in header crashes UI. Repro: ..."

Prioritizer Agent

System: Score priority 0-100 using factors: impact, blast_radius, user_pain, freshness, repro, trust. Return JSON with factors and 1-sentence rationale.


‚∏ª

16) Acceptance Criteria (v1)
	‚Ä¢	New issue ‚Üí triage comment within ‚â§30s including: labels (‚â•2), assignee/team (‚â•1), priority score, top-3 similar issues with links.
	‚Ä¢	Confidence thresholds configurable; ‚Äúauto-apply‚Äù works and logs decisions.
	‚Ä¢	Offline eval dashboard shows dupes F1 ‚â•0.8, label accuracy ‚â•0.85 on golden set.
	‚Ä¢	All actions reversible; overrides recorded in decision_log.

‚∏ª

17) Open Questions
	‚Ä¢	Use Projects v2 fields vs labels for priority?
	‚Ä¢	Per-org vs per-repo model adapters?
	‚Ä¢	Slack vs GitHub UI for approval queue (Phase 2)?

‚∏ª

Appendix: Minimal GitHub permissions (App)

Short list:
	‚Ä¢	Issues: Read & write
	‚Ä¢	Metadata: Read
	‚Ä¢	Pull requests: Read (for references)
	‚Ä¢	Contents: Read (for CODEOWNERS)
	‚Ä¢	Members/Teams: Read (for routing, if needed)
	‚Ä¢	Projects: Read & write (if used)

‚∏ª
